{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCAW58VGgX1mHCWLfodKyl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkotsche1/Image_Classification_Model_Training_Timm/blob/main/Image_Classification_Training_Timm_Library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW_fcBTM4k_S"
      },
      "outputs": [],
      "source": [
        "# !pip install barbar pytorch-ignite\n",
        "# !pip install torchvision\n",
        "# !pip install barbar\n",
        "# !pip install pytorch-ignite\n",
        "# !pip install timm\n",
        "# !pip install torchsummary\n",
        "# !pip install torchsampler\n",
        "\n",
        "import torch\n",
        "from torch import nn \n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "import timm\n",
        "import numpy as np \n",
        "from tqdm.notebook import tqdm\n",
        "import glob \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import transforms, datasets\n",
        "from shutil import copyfile, move\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from barbar import Bar\n",
        "from torchsummary import summary\n",
        "from ignite.metrics import Accuracy\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score\n",
        "from torchsampler import ImbalancedDatasetSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This requires the training data and validation data be stored in the respective folders at the root of this project ie where this notebook is located\n",
        "\n",
        "#Individual classes schould be stored as folder containing each image belonging to that class\n",
        "\n",
        "#   ./train\n",
        "#      -class1\n",
        "#         -image_class1_1.jpg\n",
        "#         -image_class1_2.jpg\n",
        "#         -image_class1_3.jpg\n",
        "#      -class2\n",
        "#         -image_class2_1.jpg\n",
        "#         -image_class2_2.jpg\n",
        "# etc. \n",
        "\n",
        "\n",
        "train_dir = \"./train\"\n",
        "valid_dir = \"./validation\"\n",
        "\n",
        "traindir = \"./train\"\n",
        "valdir = \"./validation/\"\n",
        "\n",
        "train_image_dirs = glob.glob(train_dir + \"/*/*.*\")\n",
        "valid_image_dirs = glob.glob(valid_dir + \"/*/*.*\")\n",
        "\n",
        "unique_labels = os.listdir(train_dir)\n",
        "print(unique_labels)"
      ],
      "metadata": {
        "id": "iuZqjt-O4sQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "            transforms.Resize((320,320)),\n",
        "            transforms.RandomAffine(degrees = 0, translate = (0.1, 0.1)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.RandomRotation(360),\n",
        "            transforms.RandomPerspective(distortion_scale=0.1, p=0.3, interpolation= transforms.InterpolationMode.BILINEAR, fill=0),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "     ])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((320,320)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "     traindir, transform=train_transforms)\n",
        "\n",
        "val_dataset = datasets.ImageFolder(\n",
        "    valdir, transform=val_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=32, sampler = ImbalancedDatasetSampler(train_dataset),\n",
        "    pin_memory=False, drop_last=False)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=32,sampler = ImbalancedDatasetSampler(val_dataset),\n",
        "    pin_memory=False, drop_last=False)"
      ],
      "metadata": {
        "id": "g-FzUlko45rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "LR 0 0.0001\n",
        "DROP_RATE = 0.5"
      ],
      "metadata": {
        "id": "kED2D5qo5nVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE=\"cuda\"\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "model = timm.create_model('edgenext_small', pretrained=True, num_classes = 8).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "-Q5XBHGd5DjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = 0\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            \n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when monitored metric decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Monitored metric has improved ({self.val_loss_min} --> {val_loss}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), f'path/to/save') \n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "TxPGH2QL5FRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience=200, verbose=True)\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "for epoch in EPOCHS:\n",
        "    train_loss = 0.00\n",
        "    val_loss = 0.00\n",
        "    \n",
        "    train_accuracy = Accuracy()\n",
        "    val_accuracy = Accuracy()\n",
        "    print(f'Epoch {epoch+1}')\n",
        "\n",
        "    # Training loop\n",
        "    for idx, (inputs, labels) in enumerate(Bar(train_loader)):\n",
        "        model.train()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(inputs) \n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        train_loss += loss.item()\n",
        "        train_accuracy.update((nn.functional.softmax(outputs, dim=1), labels))\n",
        "    print(f\"Train Accuracy: {train_accuracy.compute()}\")\n",
        "    train_loss /= len(train_loader)\n",
        "    train_loss_formated = \"{:.4f}\".format(train_loss)\n",
        "\n",
        "    # Validation loop\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            model.eval()           \n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_accuracy.update((nn.functional.softmax(outputs, dim=1), labels))\n",
        "    print(f\"Val Accuracy: {val_accuracy.compute()}\")\n",
        "    val_loss /= len(val_loader)\n",
        "    val_loss_formated = \"{:.4f}\".format(val_loss)\n",
        "    print(f'Training Loss: {train_loss_formated}')\n",
        "    print(f\"Validation Loss: {val_loss_formated}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    early_stopping(val_accuracy.compute(), model)       \n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break"
      ],
      "metadata": {
        "id": "VbIUvepg5LHL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}